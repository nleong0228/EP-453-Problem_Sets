# Problem Set 7
## Noah Leong
### EP-453
### 3/23/2021
## Files Included
* 02.MotionSynth
* MagnifySynth
* README.md

## Purpose 
To explore the use of core motion within a synth controller context

## Description
ProblemSet 7.1 asked to add a new View to the existing MotionSynth project. This View would take in sensor data outisde of attitudes and use the data to change color, size or placement. This view would be implemented in navigation view for the user to choose between different views.

In addition, the problemset asked to add a flanger to the synthesizer and add control for feedback and frequency using sensor data. Furthermore, It asked to add an on/off toggle switch where the user could turn the synth on or off with a single tap using TapGesture.

Finally, the problemset asked to try and build a new instrument with different controls that respond to the use in an intuitive way.

## Dependencies
This project requires the use of, AudioKit, SwiftUI, and AVFoundation

## Acknowledgement

Used the AudioKit [reference] (https://audiokit.io/docs/), and the Gestures [reference] (https://developer.apple.com/documentation/swiftui/gestures)

